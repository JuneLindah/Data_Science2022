{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#31394d'> Logistic Regression Practice Exercise </font>\n",
    "\n",
    "For this exercise we are going to use the heart dataset to predict whether or not someone will get a heart attack. You can read more about the dataset here: https://archive.ics.uci.edu/ml/datasets/Heart+Disease). The dataset is provided as a csv file in the `data` folder. \n",
    "\n",
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Start by reading in the dataset from the `data` folder and having a look at the data. Don't forget to import the necessary packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3   X4   X5  X6  X7   X8  X9  X10  X11  X12      Y\n",
       "0  63   1   1  145  233   1   2  150   0  2.3    3  0.0  False\n",
       "1  67   1   4  160  286   0   2  108   1  1.5    2  3.0   True\n",
       "2  67   1   4  120  229   0   2  129   1  2.6    2  2.0   True\n",
       "3  37   1   3  130  250   0   0  187   0  3.5    3  0.0  False\n",
       "4  41   0   2  130  204   0   2  172   0  1.4    1  0.0  False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Now standardize the features. You can learn more about standardization in the `Logistic Regression.ipynb` notebook that we used during the session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.14872617e-16 -1.78229783e-17  6.68361687e-17 -7.12919133e-17\n",
      " -6.23804241e-17 -5.04984386e-17 -4.75279422e-17  4.69338429e-16\n",
      "  1.85656024e-18 -7.12919133e-17 -4.45574458e-17 -3.56459566e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Verify that the mean of each feature is now 0 and the standard deviation is 1\n",
    "print(X.mean(axis=0))\n",
    "print(X.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Fit a standard logistic regression model and determine which features look most promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1: -0.061239983466839225\n",
      "X2: 0.8521175171444971\n",
      "X3: 0.6401165299116853\n",
      "X4: 0.4356129975064694\n",
      "X5: 0.28421529995424744\n",
      "X6: -0.29379629453707523\n",
      "X7: 0.16021017860054784\n",
      "X8: -0.489033044816707\n",
      "X9: 0.5175927985841722\n",
      "X10: 0.3199261247543762\n",
      "X11: 0.41258918993635796\n",
      "X12: 1.1111390742332032\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit a logistic regression model to the standardized data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Print the coefficient (weight) of each feature in the model\n",
    "coefficients = lr.coef_[0]\n",
    "feature_names = df.columns[:-1]\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    print(f'{feature}: {coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ <font color='#d9c4b1'> Exercise: </font> Fit another model that includes only the features that you think look promising. Use cross validation and the accuracy, precision, and recall scoring metrics to determine which model is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.76666667 0.83333333 0.75       0.75       0.79661017]\n",
      "Mean cross validation score: 0.7793220338983051\n",
      "Accuracy: 0.8060200668896321\n",
      "Precision: 0.8125\n",
      "Recall: 0.7536231884057971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Select the most promising features based on the coefficients obtained from the previous exercise\n",
    "X = df[['X1', 'X2', 'X3', 'X5', 'X7', 'X8', 'X9', 'X11']]\n",
    "\n",
    "# Standardize the selected features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Fit a logistic regression model to the standardized data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Compute the cross validation scores for the fitted model\n",
    "scores = cross_val_score(lr, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross validation scores for each fold\n",
    "print('Cross validation scores:', scores)\n",
    "print('Mean cross validation score:', scores.mean())\n",
    "\n",
    "# Make predictions on the standardized data\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "# Compute the accuracy, precision, and recall of the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "\n",
    "# Print the accuracy, precision, and recall of the model\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
